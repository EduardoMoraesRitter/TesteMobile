import SwiftUI
import CoreMotion

struct ContentView: View {
    @StateObject private var cameraRecorder = CameraRecorder()
    @StateObject private var uploader = Uploader()

    @State private var logs: [String] = []
    @State private var isProcessing = false
    @State private var locked = false

    private let motionManager = CMMotionManager()
    private let motionThreshold = 2.0

    var body: some View {
        VStack(spacing: 20) {
            Text(locked ? "üîí Prote√ß√£o Ativada" : "üü¢ Prote√ß√£o Ativa")
                .font(.title2)
                .bold()
                .foregroundColor(locked ? .red : .green)

            ScrollView {
                ForEach(logs.indices, id: \.self) { i in
                    Text(logs[i])
                        .frame(maxWidth: .infinity, alignment: .leading)
                        .font(.system(size: 14, design: .monospaced))
                        .padding(.horizontal)
                }
            }

            Spacer()
        }
        .padding()
        .onAppear {
            cameraRecorder.isBackCameraEnabled = false // üëà Desativado
            startMotionDetection()
        }
    }

    func startMotionDetection() {
        logs.append("üì° Monitorando movimento...")
        motionManager.accelerometerUpdateInterval = 0.2

        motionManager.startAccelerometerUpdates(to: .main) { data, _ in
            guard let acc = data?.acceleration else { return }

            let magnitude = sqrt(acc.x * acc.x + acc.y * acc.y + acc.z * acc.z)

            // TODO: substituir esse c√°lculo simples de magnitude
            // por um modelo local Core ML que classifica padr√µes de movimento
            // como "queda", "corrida", "arrancada" e produzir uma classifica√ß√£o
            // ex: se mlModel.predict(acceleration: [x,y,z])
            
            // Rodar um modelo Core ML continuamente em background √© dif√≠cil no iOS,
            // porque o sistema suspende o app em segundo plano ap√≥s alguns segundos
            // se n√£o houver uma tarefa ativa (como grava√ß√£o ou m√∫sica).
            // Para que funcione, o app teria que manter uma "background task"
            // ou estar usando modos especiais (ex: `audio`, `location`).

            if magnitude > motionThreshold && !isProcessing {
                logs.append("‚ö†Ô∏è Movimento brusco detectado: \(String(format: "%.2f", magnitude))")
                processSecurityFlow()
            }
        }
    }


    func processSecurityFlow() {
        logs.removeAll()
        isProcessing = true
        locked = false

        logs.append("üé• Gravando c√¢mera frontal com √°udio...")
        let userName = UIDevice.current.name

        cameraRecorder.recordFrontCamera(duration: 4) { frontURL in
            guard let front = frontURL else {
                logs.append("‚ùå Erro ao gravar a c√¢mera frontal.")
                isProcessing = false
                return
            }

            logs.append("‚úÖ V√≠deo frontal gravado: \(front.lastPathComponent)")
            logs.append("üì§ Enviando v√≠deo frontal...")

            uploader.uploadVideo(fileURL: front, userName: userName, isFrontCamera: true) { success, frontPublicURL in
                if success {
                    logs.append("‚úÖ Upload frontal OK")
                } else {
                    logs.append("‚ùå Upload frontal falhou")
                    isProcessing = false
                    return
                }

                logs.append("üß† Enviando para an√°lise de seguran√ßa...")

                uploader.analyzeVideos(frontURL: frontPublicURL, backURL: "") { isSafe, message in
                    logs.append("üìä Resultado da IA: \(message)")
                    if !isSafe {
                        logs.append("üîí Dispositivo bloqueado (simulado)")
                        locked = true
                    } else {
                        logs.append("‚úÖ Nenhum risco detectado")
                    }
                    isProcessing = false
                }
            }
        }
    }
}
